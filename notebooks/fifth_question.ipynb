{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed5d8f79-d770-4cd3-9494-05773345b72d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'conf': {'spark.sql.catalog.spark_catalog.type': 'hive', 'spark.executor.instances': '2', 'spark.executor.cores': '4', 'spark.executor.memory': '8g'}, 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>1720</td><td>application_1765289937462_1704</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_1704/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-115.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_1704_01_000002/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>1751</td><td>application_1765289937462_1735</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_1735/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-91.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_1735_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>1753</td><td>application_1765289937462_1737</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_1737/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-115.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_1737_01_000002/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>1756</td><td>application_1765289937462_1740</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_1740/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-48.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_1740_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>1758</td><td>application_1765289937462_1742</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_1742/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-149.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_1742_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>1759</td><td>application_1765289937462_1743</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_1743/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-115.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_1743_01_000002/livy\">Link</a></td><td>None</td><td></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure -f\n",
    "{\n",
    "  \"conf\": {\n",
    "    \"spark.executor.instances\": \"2\",\n",
    "    \"spark.executor.cores\": \"4\",\n",
    "    \"spark.executor.memory\": \"8g\"\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db39bf4c-2c96-45c9-bac4-dce5342710e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'conf': {'spark.sql.catalog.spark_catalog.type': 'hive', 'spark.executor.instances': '4', 'spark.executor.cores': '2', 'spark.executor.memory': '4g'}, 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>1266</td><td>application_1765289937462_1256</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_1256/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-207.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_1256_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>1268</td><td>application_1765289937462_1258</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_1258/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-48.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_1258_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>1269</td><td>application_1765289937462_1259</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_1259/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-131.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_1259_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>1273</td><td>application_1765289937462_1263</td><td>pyspark</td><td>busy</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_1263/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-131.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_1263_01_000001/livy\">Link</a></td><td>None</td><td></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure -f\n",
    "{\n",
    "  \"conf\": {\n",
    "    \"spark.executor.instances\": \"4\",\n",
    "    \"spark.executor.cores\": \"2\",\n",
    "    \"spark.executor.memory\": \"4g\"\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f672a29-43e9-494f-bac2-5be3dfe77c7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Current session configs: <tt>{'conf': {'spark.sql.catalog.spark_catalog.type': 'hive', 'spark.executor.instances': '8', 'spark.executor.cores': '1', 'spark.executor.memory': '2g'}, 'kind': 'pyspark'}</tt><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>1266</td><td>application_1765289937462_1256</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_1256/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-207.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_1256_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>1268</td><td>application_1765289937462_1258</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_1258/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-48.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_1258_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>1269</td><td>application_1765289937462_1259</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_1259/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-131.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_1259_01_000001/livy\">Link</a></td><td>None</td><td></td></tr><tr><td>1273</td><td>application_1765289937462_1263</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_1263/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-131.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_1263_01_000001/livy\">Link</a></td><td>None</td><td></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%configure -f\n",
    "{\n",
    "  \"conf\": {\n",
    "    \"spark.executor.instances\": \"8\",\n",
    "    \"spark.executor.cores\": \"1\",\n",
    "    \"spark.executor.memory\": \"2g\"\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56e8b40d-7f54-4e28-b416-3103c50ea2a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>1276</td><td>application_1765289937462_1266</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_1266/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-30.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_1266_01_000001/livy\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b421e20e841e4f41a4f0a6c98f370a7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d41a7195c5a748b182325ca5d31db66a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executors = 8\n",
      "cores/exec = 1\n",
      "mem/exec   = 2g"
     ]
    }
   ],
   "source": [
    "# Configuration switch check\n",
    "print(\"executors =\", spark.conf.get(\"spark.executor.instances\", \"n/a\"))\n",
    "print(\"cores/exec =\", spark.conf.get(\"spark.executor.cores\", \"n/a\"))\n",
    "print(\"mem/exec   =\", spark.conf.get(\"spark.executor.memory\", \"n/a\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc7fb132-abd7-4c4e-a106-202e4ae8fa15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Spark application\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>User</th><th>Current session?</th></tr><tr><td>1760</td><td>application_1765289937462_1744</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-192-168-1-63.eu-central-1.compute.internal:20888/proxy/application_1765289937462_1744/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-192-168-1-213.eu-central-1.compute.internal:8042/node/containerlogs/container_1765289937462_1744_01_000001/livy\">Link</a></td><td>None</td><td>✔</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e509233ecd84ff0b37acbebc6f0be35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparkSession available as 'spark'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa48f56fba304d7688811a8604af4476",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FloatProgress(value=0.0, bar_style='info', description='Progress:', layout=Layout(height='25px', width='50%'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Sedona registered OK\n",
      ">>> crimes total rows: 3138128\n",
      ">>> [timing] Load & union crimes (count) took 14.03s\n",
      ">>> crimes schema:\n",
      "root\n",
      " |-- DR_NO: string (nullable = true)\n",
      " |-- Date Rptd: string (nullable = true)\n",
      " |-- DATE OCC: string (nullable = true)\n",
      " |-- TIME OCC: string (nullable = true)\n",
      " |-- AREA: string (nullable = true)\n",
      " |-- AREA NAME: string (nullable = true)\n",
      " |-- Rpt Dist No: string (nullable = true)\n",
      " |-- Part 1-2: string (nullable = true)\n",
      " |-- Crm Cd: string (nullable = true)\n",
      " |-- Crm Cd Desc: string (nullable = true)\n",
      " |-- Mocodes: string (nullable = true)\n",
      " |-- Vict Age: string (nullable = true)\n",
      " |-- Vict Sex: string (nullable = true)\n",
      " |-- Vict Descent: string (nullable = true)\n",
      " |-- Premis Cd: string (nullable = true)\n",
      " |-- Premis Desc: string (nullable = true)\n",
      " |-- Weapon Used Cd: string (nullable = true)\n",
      " |-- Weapon Desc: string (nullable = true)\n",
      " |-- Status: string (nullable = true)\n",
      " |-- Status Desc: string (nullable = true)\n",
      " |-- Crm Cd 1: string (nullable = true)\n",
      " |-- Crm Cd 2: string (nullable = true)\n",
      " |-- Crm Cd 3: string (nullable = true)\n",
      " |-- Crm Cd 4: string (nullable = true)\n",
      " |-- LOCATION: string (nullable = true)\n",
      " |-- Cross Street: string (nullable = true)\n",
      " |-- LAT: string (nullable = true)\n",
      " |-- LON: string (nullable = true)\n",
      "\n",
      ">>> crimes selected cols schema:\n",
      "root\n",
      " |-- DR_NO: string (nullable = true)\n",
      " |-- DATE OCC: string (nullable = true)\n",
      " |-- LAT: string (nullable = true)\n",
      " |-- LON: string (nullable = true)\n",
      "\n",
      ">>> crimes with YEAR_OCC sample:\n",
      "+---------+-----------------------+-------------------+--------+\n",
      "|DR_NO    |DATE OCC               |DATE_OCC_TS        |YEAR_OCC|\n",
      "+---------+-----------------------+-------------------+--------+\n",
      "|001307355|2010 Feb 20 12:00:00 AM|2010-02-20 00:00:00|2010    |\n",
      "|011401303|2010 Sep 12 12:00:00 AM|2010-09-12 00:00:00|2010    |\n",
      "|070309629|2010 Aug 09 12:00:00 AM|2010-08-09 00:00:00|2010    |\n",
      "|090631215|2010 Jan 05 12:00:00 AM|2010-01-05 00:00:00|2010    |\n",
      "|100100501|2010 Jan 02 12:00:00 AM|2010-01-02 00:00:00|2010    |\n",
      "|100100506|2010 Jan 04 12:00:00 AM|2010-01-04 00:00:00|2010    |\n",
      "|100100508|2010 Jan 07 12:00:00 AM|2010-01-07 00:00:00|2010    |\n",
      "|100100509|2010 Jan 08 12:00:00 AM|2010-01-08 00:00:00|2010    |\n",
      "|100100510|2010 Jan 09 12:00:00 AM|2010-01-09 00:00:00|2010    |\n",
      "|100100511|2010 Jan 06 12:00:00 AM|2010-01-06 00:00:00|2010    |\n",
      "+---------+-----------------------+-------------------+--------+\n",
      "only showing top 10 rows\n",
      "\n",
      ">>> [timing] Derive YEAR_OCC (show) took 0.59s\n",
      ">>> crimes_2020_2021 rows after year filter: 409723\n",
      ">>> [timing] Filter 2020?2021 (count) took 4.39s\n",
      ">>> crimes_2020_2021 rows after coord filters: 407488\n",
      "+---------+--------+-------+---------+\n",
      "|DR_NO    |YEAR_OCC|LAT_D  |LON_D    |\n",
      "+---------+--------+-------+---------+\n",
      "|211507896|2020    |34.2124|-118.4092|\n",
      "|201516622|2020    |34.1993|-118.4203|\n",
      "|240913563|2020    |34.1847|-118.4509|\n",
      "|210704711|2020    |34.0339|-118.3747|\n",
      "|201418201|2020    |33.9813|-118.435 |\n",
      "|240412063|2020    |34.083 |-118.1678|\n",
      "|240317069|2020    |34.01  |-118.29  |\n",
      "|201115217|2020    |34.1107|-118.2589|\n",
      "|241708596|2020    |34.2763|-118.521 |\n",
      "|242113813|2020    |34.1493|-118.5886|\n",
      "+---------+--------+-------+---------+\n",
      "only showing top 10 rows\n",
      "\n",
      ">>> [timing] Clean coords (count+show) took 10.79s\n",
      ">>> crimes_geom rows: 407488\n",
      "+---------+--------+-------------------------+\n",
      "|crime_id |YEAR_OCC|crime_geom               |\n",
      "+---------+--------+-------------------------+\n",
      "|211507896|2020    |POINT (-118.4092 34.2124)|\n",
      "|201516622|2020    |POINT (-118.4203 34.1993)|\n",
      "|240913563|2020    |POINT (-118.4509 34.1847)|\n",
      "|210704711|2020    |POINT (-118.3747 34.0339)|\n",
      "|201418201|2020    |POINT (-118.435 33.9813) |\n",
      "+---------+--------+-------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      ">>> [timing] Build crimes_geom (count+show) took 8.96s\n",
      ">>> blocks_raw schema:\n",
      "root\n",
      " |-- crs: struct (nullable = true)\n",
      " |    |-- properties: struct (nullable = true)\n",
      " |    |    |-- name: string (nullable = true)\n",
      " |    |-- type: string (nullable = true)\n",
      " |-- features: array (nullable = true)\n",
      " |    |-- element: struct (containsNull = true)\n",
      " |    |    |-- geometry: struct (nullable = true)\n",
      " |    |    |    |-- coordinates: array (nullable = true)\n",
      " |    |    |    |    |-- element: array (containsNull = true)\n",
      " |    |    |    |    |    |-- element: array (containsNull = true)\n",
      " |    |    |    |    |    |    |-- element: string (containsNull = true)\n",
      " |    |    |    |-- type: string (nullable = true)\n",
      " |    |    |-- properties: struct (nullable = true)\n",
      " |    |    |    |-- BG20: string (nullable = true)\n",
      " |    |    |    |-- BG20FIP_CURRENT: string (nullable = true)\n",
      " |    |    |    |-- BGFIP20: string (nullable = true)\n",
      " |    |    |    |-- CB20: string (nullable = true)\n",
      " |    |    |    |-- CITY: string (nullable = true)\n",
      " |    |    |    |-- CITYCOMM: string (nullable = true)\n",
      " |    |    |    |-- CITYCOMM_CURRENT: string (nullable = true)\n",
      " |    |    |    |-- CITY_CURRENT: string (nullable = true)\n",
      " |    |    |    |-- COMM: string (nullable = true)\n",
      " |    |    |    |-- COMM_CURRENT: string (nullable = true)\n",
      " |    |    |    |-- COUNTY: string (nullable = true)\n",
      " |    |    |    |-- CT20: string (nullable = true)\n",
      " |    |    |    |-- CTCB20: string (nullable = true)\n",
      " |    |    |    |-- FEAT_TYPE: string (nullable = true)\n",
      " |    |    |    |-- FIP20: string (nullable = true)\n",
      " |    |    |    |-- FIP_CURRENT: string (nullable = true)\n",
      " |    |    |    |-- HD22: long (nullable = true)\n",
      " |    |    |    |-- HD_NAME: string (nullable = true)\n",
      " |    |    |    |-- HOUSING20: long (nullable = true)\n",
      " |    |    |    |-- OBJECTID: long (nullable = true)\n",
      " |    |    |    |-- POP20: long (nullable = true)\n",
      " |    |    |    |-- SPA22: long (nullable = true)\n",
      " |    |    |    |-- SPA_NAME: string (nullable = true)\n",
      " |    |    |    |-- SUP21: string (nullable = true)\n",
      " |    |    |    |-- SUP_LABEL: string (nullable = true)\n",
      " |    |    |    |-- ShapeSTArea: double (nullable = true)\n",
      " |    |    |    |-- ShapeSTLength: double (nullable = true)\n",
      " |    |    |    |-- State: string (nullable = true)\n",
      " |    |    |    |-- ZCTA20: string (nullable = true)\n",
      " |    |    |-- type: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      "\n",
      "+--------------------+--------------------+------------------+-----------------+\n",
      "|                 crs|            features|              name|             type|\n",
      "+--------------------+--------------------+------------------+-----------------+\n",
      "|{{urn:ogc:def:crs...|[{{[[[-118.480230...|2020_Census_Blocks|FeatureCollection|\n",
      "+--------------------+--------------------+------------------+-----------------+\n",
      "\n",
      ">>> blocks_features rows: 91626\n",
      ">>> [timing] Read census geojson (count) took 32.22s\n",
      ">>> sample geom_json_str (fixed):\n",
      "+--------------------+\n",
      "|       geom_json_str|\n",
      "+--------------------+\n",
      "|{\"type\": \"Polygon...|\n",
      "|{\"type\": \"Polygon...|\n",
      "|{\"type\": \"Polygon...|\n",
      "+--------------------+\n",
      "only showing top 3 rows\n",
      "\n",
      ">>> blocks rows after filters: 42565\n",
      ">>> [timing] Build blocks (count) took 38.88s\n",
      "root\n",
      " |-- COMM: string (nullable = true)\n",
      " |-- ZCTA20: string (nullable = true)\n",
      " |-- POP20: double (nullable = true)\n",
      " |-- HOUSING20: double (nullable = true)\n",
      " |-- geom: geometry (nullable = true)\n",
      "\n",
      "+--------+--------+-----+\n",
      "|is_valid|is_empty|count|\n",
      "+--------+--------+-----+\n",
      "|    true|   false|42565|\n",
      "+--------+--------+-----+\n",
      "\n",
      ">>> [timing] QC blocks (show) took 1.52s\n",
      ">>> income schema (raw):\n",
      "root\n",
      " |-- Zip Code: string (nullable = true)\n",
      " |-- Community: string (nullable = true)\n",
      " |-- Estimated Median Income: string (nullable = true)\n",
      "\n",
      "+--------+--------------------------------------------------------------------------------------------+-----------------------+\n",
      "|Zip Code|Community                                                                                   |Estimated Median Income|\n",
      "+--------+--------------------------------------------------------------------------------------------+-----------------------+\n",
      "|90001   |Los Angeles (South Los Angeles), Florence-Graham                                            |$52,806                |\n",
      "|90002   |Los Angeles (Southeast Los Angeles, Watts)                                                  |$46,159                |\n",
      "|90003   |Los Angeles (South Los Angeles, Southeast Los Angeles)                                      |$47,733                |\n",
      "|90004   |Los Angeles (Hancock Park, Rampart Village, Virgil Village, Wilshire Center, Windsor Square)|$54,947                |\n",
      "|90005   |Los Angeles (Hancock Park, Koreatown, Wilshire Center, Wilshire Park, Windsor Square)       |$44,913                |\n",
      "|90006   |Los Angeles (Byzantine-Latino Quarter, Harvard Heights, Koreatown, Pico Heights)            |$41,068                |\n",
      "|90007   |Los Angeles (Southeast Los Angeles, Univerity Park)                                         |$33,222                |\n",
      "|90008   |Los Angeles (Baldwin Hills, Crenshaw, Leimert Park)                                         |$49,379                |\n",
      "|90010   |Los Angeles (Hancock Park, Wilshire Center, Windsor Square)                                 |$76,547                |\n",
      "|90011   |Los Angeles (Southeast Los Angeles)                                                         |$47,126                |\n",
      "+--------+--------------------------------------------------------------------------------------------+-----------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      ">>> income cleaned schema:\n",
      "root\n",
      " |-- ZIP: string (nullable = true)\n",
      " |-- Community_name: string (nullable = true)\n",
      " |-- EstimatedMedianIncome_raw: string (nullable = true)\n",
      " |-- median_income_household: double (nullable = true)\n",
      " |-- ZIP_norm: string (nullable = true)\n",
      "\n",
      "+-----+--------+-----------------------+\n",
      "|ZIP  |ZIP_norm|median_income_household|\n",
      "+-----+--------+-----------------------+\n",
      "|90001|90001   |52806.0                |\n",
      "|90002|90002   |46159.0                |\n",
      "|90003|90003   |47733.0                |\n",
      "|90004|90004   |54947.0                |\n",
      "|90005|90005   |44913.0                |\n",
      "|90006|90006   |41068.0                |\n",
      "|90007|90007   |33222.0                |\n",
      "|90008|90008   |49379.0                |\n",
      "|90010|90010   |76547.0                |\n",
      "|90011|90011   |47126.0                |\n",
      "+-----+--------+-----------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      ">>> [timing] Prepare income (show) took 0.83s\n",
      ">>> blocks rows (with ZCTA20_norm): 42063\n",
      ">>> blocks_income rows (after left join): 42063\n",
      ">>> [timing] Join ZCTA ? ZIP (counts) took 1.12s\n",
      "+-------------+------+-----------+-----------------------+\n",
      "|COMM         |ZCTA20|ZCTA20_norm|median_income_household|\n",
      "+-------------+------+-----------+-----------------------+\n",
      "|Granada Hills|91344 |91344      |104640.0               |\n",
      "|Granada Hills|91344 |91344      |104640.0               |\n",
      "|Granada Hills|91344 |91344      |104640.0               |\n",
      "|Granada Hills|91344 |91344      |104640.0               |\n",
      "|Chatsworth   |91311 |91311      |101623.0               |\n",
      "|Chatsworth   |91311 |91311      |101623.0               |\n",
      "|Granada Hills|91344 |91344      |104640.0               |\n",
      "|Granada Hills|91344 |91344      |104640.0               |\n",
      "|Pacoima      |91331 |91331      |72089.0                |\n",
      "|Sunland      |91342 |91342      |84312.0                |\n",
      "+-------------+------+-----------+-----------------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "\n",
      "== Spark plan: ZCTA ? ZIP (blocks_norm ? income_for_join) ==\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan (19)\n",
      "+- BroadcastHashJoin LeftOuter BuildRight (18)\n",
      "   :- Project (13)\n",
      "   :  +- Filter (12)\n",
      "   :     +- InMemoryTableScan (1)\n",
      "   :           +- InMemoryRelation (2)\n",
      "   :                 +- Project (11)\n",
      "   :                    +- BatchEvalPython (10)\n",
      "   :                       +- * Project (9)\n",
      "   :                          +- Filter (8)\n",
      "   :                             +- BatchEvalPython (7)\n",
      "   :                                +- * Filter (6)\n",
      "   :                                   +- * Generate (5)\n",
      "   :                                      +- * Filter (4)\n",
      "   :                                         +- Scan json  (3)\n",
      "   +- BroadcastExchange (17)\n",
      "      +- Project (16)\n",
      "         +- Filter (15)\n",
      "            +- Scan csv  (14)\n",
      "\n",
      "\n",
      "(1) InMemoryTableScan\n",
      "Output [5]: [COMM#778, HOUSING20#767, POP20#766, ZCTA20#765, geom#768]\n",
      "Arguments: [COMM#778, HOUSING20#767, POP20#766, ZCTA20#765, geom#768], [isnotnull(regexp_replace(trim(ZCTA20#765, None), [^0-9], , 1)), NOT (regexp_replace(trim(ZCTA20#765, None), [^0-9], , 1) = )]\n",
      "\n",
      "(2) InMemoryRelation\n",
      "Arguments: [COMM#778, ZCTA20#765, POP20#766, HOUSING20#767, geom#768], CachedRDDBuilder(org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer@a8621de,StorageLevel(disk, memory, deserialized, 1 replicas),Project [trim(feature#731.properties.COMM, None) AS COMM#778, feature#731.properties.ZCTA20 AS ZCTA20#765, cast(feature#731.properties.POP20 as double) AS POP20#766, cast(feature#731.properties.HOUSING20 as double) AS HOUSING20#767,  **org.apache.spark.sql.sedona_sql.expressions.ST_MakeValid**   AS geom#768]\n",
      "+- BatchEvalPython [fix_geom(feature#731.geometry)#746], [pythonUDF0#790]\n",
      "   +- *(2) Project [feature#731]\n",
      "      +- Filter ((isnotnull(pythonUDF0#789) AND isnotnull( **org.apache.spark.sql.sedona_sql.expressions.ST_MakeValid**  )) AND NOT  **org.apache.spark.sql.sedona_sql.expressions.ST_IsEmpty**  )\n",
      "         +- BatchEvalPython [fix_geom(feature#731.geometry)#746], [pythonUDF0#789]\n",
      "            +- *(1) Filter (((((isnotnull(feature#731.properties.POP20) AND isnotnull(feature#731.properties.HOUSING20)) AND isnotnull(trim(feature#731.properties.COMM, None))) AND NOT (trim(feature#731.properties.COMM, None) = )) AND isnotnull(cast(feature#731.properties.POP20 as double))) AND isnotnull(cast(feature#731.properties.HOUSING20 as double)))\n",
      "               +- *(1) Generate explode(features#697), false, [feature#731]\n",
      "                  +- *(1) Filter ((size(features#697, true) > 0) AND isnotnull(features#697))\n",
      "                     +- FileScan json [features#697] Batched: false, DataFilters: [(size(features#697, true) > 0), isnotnull(features#697)], Format: JSON, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_C..., PartitionFilters: [], PushedFilters: [IsNotNull(features)], ReadSchema: struct<features:array<struct<geometry:struct<coordinates:array<array<array<string>>>,type:string>...\n",
      ",None)\n",
      "\n",
      "(3) Scan json \n",
      "Output [1]: [features#697]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Census_Blocks_2020.geojson]\n",
      "PushedFilters: [IsNotNull(features)]\n",
      "ReadSchema: struct<features:array<struct<geometry:struct<coordinates:array<array<array<string>>>,type:string>,properties:struct<BG20:string,BG20FIP_CURRENT:string,BGFIP20:string,CB20:string,CITY:string,CITYCOMM:string,CITYCOMM_CURRENT:string,CITY_CURRENT:string,COMM:string,COMM_CURRENT:string,COUNTY:string,CT20:string,CTCB20:string,FEAT_TYPE:string,FIP20:string,FIP_CURRENT:string,HD22:bigint,HD_NAME:string,HOUSING20:bigint,OBJECTID:bigint,POP20:bigint,SPA22:bigint,SPA_NAME:string,SUP21:string,SUP_LABEL:string,ShapeSTArea:double,ShapeSTLength:double,State:string,ZCTA20:string>,type:string>>>\n",
      "\n",
      "(4) Filter [codegen id : 1]\n",
      "Input [1]: [features#697]\n",
      "Condition : ((size(features#697, true) > 0) AND isnotnull(features#697))\n",
      "\n",
      "(5) Generate [codegen id : 1]\n",
      "Input [1]: [features#697]\n",
      "Arguments: explode(features#697), false, [feature#731]\n",
      "\n",
      "(6) Filter [codegen id : 1]\n",
      "Input [1]: [feature#731]\n",
      "Condition : (((((isnotnull(feature#731.properties.POP20) AND isnotnull(feature#731.properties.HOUSING20)) AND isnotnull(trim(feature#731.properties.COMM, None))) AND NOT (trim(feature#731.properties.COMM, None) = )) AND isnotnull(cast(feature#731.properties.POP20 as double))) AND isnotnull(cast(feature#731.properties.HOUSING20 as double)))\n",
      "\n",
      "(7) BatchEvalPython\n",
      "Input [1]: [feature#731]\n",
      "Arguments: [fix_geom(feature#731.geometry)#746], [pythonUDF0#789]\n",
      "\n",
      "(8) Filter\n",
      "Input [2]: [feature#731, pythonUDF0#789]\n",
      "Condition : ((isnotnull(pythonUDF0#789) AND isnotnull( **org.apache.spark.sql.sedona_sql.expressions.ST_MakeValid**  )) AND NOT  **org.apache.spark.sql.sedona_sql.expressions.ST_IsEmpty**  )\n",
      "\n",
      "(9) Project [codegen id : 2]\n",
      "Output [1]: [feature#731]\n",
      "Input [2]: [feature#731, pythonUDF0#789]\n",
      "\n",
      "(10) BatchEvalPython\n",
      "Input [1]: [feature#731]\n",
      "Arguments: [fix_geom(feature#731.geometry)#746], [pythonUDF0#790]\n",
      "\n",
      "(11) Project\n",
      "Output [5]: [trim(feature#731.properties.COMM, None) AS COMM#778, feature#731.properties.ZCTA20 AS ZCTA20#765, cast(feature#731.properties.POP20 as double) AS POP20#766, cast(feature#731.properties.HOUSING20 as double) AS HOUSING20#767,  **org.apache.spark.sql.sedona_sql.expressions.ST_MakeValid**   AS geom#768]\n",
      "Input [2]: [feature#731, pythonUDF0#790]\n",
      "\n",
      "(12) Filter\n",
      "Input [5]: [COMM#778, HOUSING20#767, POP20#766, ZCTA20#765, geom#768]\n",
      "Condition : (isnotnull(regexp_replace(trim(ZCTA20#765, None), [^0-9], , 1)) AND NOT (regexp_replace(trim(ZCTA20#765, None), [^0-9], , 1) = ))\n",
      "\n",
      "(13) Project\n",
      "Output [6]: [COMM#778, ZCTA20#765, POP20#766, HOUSING20#767, geom#768, regexp_replace(trim(ZCTA20#765, None), [^0-9], , 1) AS ZCTA20_norm#1236]\n",
      "Input [5]: [COMM#778, HOUSING20#767, POP20#766, ZCTA20#765, geom#768]\n",
      "\n",
      "(14) Scan csv \n",
      "Output [2]: [Zip Code#1175, Estimated Median Income#1177]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_income_2021.csv]\n",
      "PushedFilters: [IsNotNull(Estimated Median Income)]\n",
      "ReadSchema: struct<Zip Code:string,Estimated Median Income:string>\n",
      "\n",
      "(15) Filter\n",
      "Input [2]: [Zip Code#1175, Estimated Median Income#1177]\n",
      "Condition : (((isnotnull(Estimated Median Income#1177) AND isnotnull(cast(regexp_replace(Estimated Median Income#1177, [$,], , 1) as double))) AND NOT (regexp_replace(trim(Zip Code#1175, None), [^0-9], , 1) = )) AND isnotnull(regexp_replace(trim(Zip Code#1175, None), [^0-9], , 1)))\n",
      "\n",
      "(16) Project\n",
      "Output [2]: [regexp_replace(trim(Zip Code#1175, None), [^0-9], , 1) AS ZIP_norm#1209, cast(regexp_replace(Estimated Median Income#1177, [$,], , 1) as double) AS median_income_household#1204]\n",
      "Input [2]: [Zip Code#1175, Estimated Median Income#1177]\n",
      "\n",
      "(17) BroadcastExchange\n",
      "Input [2]: [ZIP_norm#1209, median_income_household#1204]\n",
      "Arguments: HashedRelationBroadcastMode(List(input[0, string, true]),false), [plan_id=1240]\n",
      "\n",
      "(18) BroadcastHashJoin\n",
      "Left keys [1]: [ZCTA20_norm#1236]\n",
      "Right keys [1]: [ZIP_norm#1209]\n",
      "Join type: LeftOuter\n",
      "Join condition: None\n",
      "\n",
      "(19) AdaptiveSparkPlan\n",
      "Output [8]: [COMM#778, ZCTA20#765, POP20#766, HOUSING20#767, geom#768, ZCTA20_norm#1236, ZIP_norm#1209, median_income_household#1204]\n",
      "Arguments: isFinalPlan=false\n",
      "\n",
      "\n",
      ">>> [timing] Explain ZCTA ? ZIP took 0.47s\n",
      ">>> blocks_by_comm rows: 255\n",
      ">>> [timing] Aggregate by COMM (count) took 0.65s\n",
      "+--------------------------------------+---------+----------------+-----------------------+------------------+\n",
      "|COMM                                  |total_pop|total_households|mean_household_income_w|per_capita_income |\n",
      "+--------------------------------------+---------+----------------+-----------------------+------------------+\n",
      "|Franklin Canyon                       |1.0      |1.0             |154740.0               |154740.0          |\n",
      "|Palos Verdes Peninsula                |719.0    |389.0           |186144.0               |100709.34075104311|\n",
      "|Marina del Rey                        |11342.0  |8064.0          |137813.0               |97983.0745900194  |\n",
      "|Pacific Palisades                     |20952.0  |9134.0          |201286.29362820231     |87750.52529591447 |\n",
      "|Marina Peninsula                      |4903.0   |3045.0          |137813.0               |85588.53457067102 |\n",
      "|Palisades Highlands                   |3911.0   |1541.0          |212115.0               |83576.88954231654 |\n",
      "|Playa Vista                           |16230.0  |8681.0          |152708.7269899781      |81679.88040665434 |\n",
      "|Bel Air                               |7748.0   |3370.0          |184877.72255192877     |80412.74199793495 |\n",
      "|Santa Catalina Island                 |255.0    |246.0           |77644.0                |74903.62352941177 |\n",
      "|Brentwood                             |30334.0  |15482.0         |142924.34491667742     |72946.3541900178  |\n",
      "|Beverly Crest                         |11918.0  |5331.0          |155753.44363158883     |69669.54254069475 |\n",
      "|Westfield/Academy Hills               |1396.0   |510.0           |186144.0               |68003.89684813753 |\n",
      "|Mandeville Canyon                     |3242.0   |1301.0          |164143.55880092236     |65870.0709438618  |\n",
      "|Venice                                |33444.0  |19195.0         |110534.63969783798     |63440.7489833752  |\n",
      "|Carthay                               |14080.0  |8575.0          |103084.16676384839     |62780.30752840909 |\n",
      "|Bouquet Canyon                        |1105.0   |509.0           |131844.673870334       |60732.07149321267 |\n",
      "|San Francisquito Canyon/Bouquet Canyon|325.0    |148.0           |133150.0               |60634.46153846154 |\n",
      "|Playa Del Rey                         |2958.0   |1611.0          |110884.0               |60390.17038539554 |\n",
      "|Century City                          |13600.0  |7564.0          |105908.50330512956     |58903.81757352941 |\n",
      "|Padua Hills                           |126.0    |66.0            |112430.0               |58891.90476190476 |\n",
      "+--------------------------------------+---------+----------------+-----------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      ">>> Running spatial join ... contains\n",
      "\n",
      "== Spark plan: Spatial join (crimes_geom ? blocks_geom) ==\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan (22)\n",
      "+- Project (21)\n",
      "   +- RangeJoin (20)\n",
      "      :- Union (7)\n",
      "      :  :- Project (3)\n",
      "      :  :  +- Filter (2)\n",
      "      :  :     +- Scan csv  (1)\n",
      "      :  +- Project (6)\n",
      "      :     +- Filter (5)\n",
      "      :        +- Scan csv  (4)\n",
      "      +- Filter (19)\n",
      "         +- InMemoryTableScan (8)\n",
      "               +- InMemoryRelation (9)\n",
      "                     +- Project (18)\n",
      "                        +- BatchEvalPython (17)\n",
      "                           +- * Project (16)\n",
      "                              +- Filter (15)\n",
      "                                 +- BatchEvalPython (14)\n",
      "                                    +- * Filter (13)\n",
      "                                       +- * Generate (12)\n",
      "                                          +- * Filter (11)\n",
      "                                             +- Scan json  (10)\n",
      "\n",
      "\n",
      "(1) Scan csv \n",
      "Output [4]: [DR_NO#42, DATE OCC#44, LAT#68, LON#69]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Crime_Data/LA_Crime_Data_2010_2019.csv]\n",
      "PushedFilters: [IsNotNull(LAT), IsNotNull(LON)]\n",
      "ReadSchema: struct<DR_NO:string,DATE OCC:string,LAT:string,LON:string>\n",
      "\n",
      "(2) Filter\n",
      "Input [4]: [DR_NO#42, DATE OCC#44, LAT#68, LON#69]\n",
      "Condition : (((((((isnotnull(LAT#68) AND isnotnull(LON#69)) AND (year(cast(gettimestamp(DATE OCC#44, yyyy MMM dd hh:mm:ss a, TimestampType, Some(UTC), false) as date)) >= 2020)) AND (year(cast(gettimestamp(DATE OCC#44, yyyy MMM dd hh:mm:ss a, TimestampType, Some(UTC), false) as date)) <= 2021)) AND isnotnull(cast(LAT#68 as double))) AND isnotnull(cast(LON#69 as double))) AND (NOT (cast(LAT#68 as double) = 0.0) OR NOT (cast(LON#69 as double) = 0.0))) AND isnotnull( **org.apache.spark.sql.sedona_sql.expressions.ST_Point**  ))\n",
      "\n",
      "(3) Project\n",
      "Output [3]: [DR_NO#42 AS crime_id#536, year(cast(gettimestamp(DATE OCC#44, yyyy MMM dd hh:mm:ss a, TimestampType, Some(UTC), false) as date)) AS YEAR_OCC#244,  **org.apache.spark.sql.sedona_sql.expressions.ST_Point**   AS crime_geom#537]\n",
      "Input [4]: [DR_NO#42, DATE OCC#44, LAT#68, LON#69]\n",
      "\n",
      "(4) Scan csv \n",
      "Output [4]: [DR_NO#116, DATE OCC#118, LAT#142, LON#143]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Crime_Data/LA_Crime_Data_2020_2025.csv]\n",
      "PushedFilters: [IsNotNull(LAT), IsNotNull(LON)]\n",
      "ReadSchema: struct<DR_NO:string,DATE OCC:string,LAT:string,LON:string>\n",
      "\n",
      "(5) Filter\n",
      "Input [4]: [DR_NO#116, DATE OCC#118, LAT#142, LON#143]\n",
      "Condition : (((((((isnotnull(LAT#142) AND isnotnull(LON#143)) AND (year(cast(gettimestamp(DATE OCC#118, yyyy MMM dd hh:mm:ss a, TimestampType, Some(UTC), false) as date)) >= 2020)) AND (year(cast(gettimestamp(DATE OCC#118, yyyy MMM dd hh:mm:ss a, TimestampType, Some(UTC), false) as date)) <= 2021)) AND isnotnull(cast(LAT#142 as double))) AND isnotnull(cast(LON#143 as double))) AND (NOT (cast(LAT#142 as double) = 0.0) OR NOT (cast(LON#143 as double) = 0.0))) AND isnotnull( **org.apache.spark.sql.sedona_sql.expressions.ST_Point**  ))\n",
      "\n",
      "(6) Project\n",
      "Output [3]: [DR_NO#116 AS crime_id#2289, year(cast(gettimestamp(DATE OCC#118, yyyy MMM dd hh:mm:ss a, TimestampType, Some(UTC), false) as date)) AS YEAR_OCC#2286,  **org.apache.spark.sql.sedona_sql.expressions.ST_Point**   AS crime_geom#2290]\n",
      "Input [4]: [DR_NO#116, DATE OCC#118, LAT#142, LON#143]\n",
      "\n",
      "(7) Union\n",
      "\n",
      "(8) InMemoryTableScan\n",
      "Output [2]: [COMM#778, geom#768]\n",
      "Arguments: [COMM#778, geom#768], [isnotnull(geom#768)]\n",
      "\n",
      "(9) InMemoryRelation\n",
      "Arguments: [COMM#778, ZCTA20#765, POP20#766, HOUSING20#767, geom#768], CachedRDDBuilder(org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer@a8621de,StorageLevel(disk, memory, deserialized, 1 replicas),Project [trim(feature#731.properties.COMM, None) AS COMM#778, feature#731.properties.ZCTA20 AS ZCTA20#765, cast(feature#731.properties.POP20 as double) AS POP20#766, cast(feature#731.properties.HOUSING20 as double) AS HOUSING20#767,  **org.apache.spark.sql.sedona_sql.expressions.ST_MakeValid**   AS geom#768]\n",
      "+- BatchEvalPython [fix_geom(feature#731.geometry)#746], [pythonUDF0#790]\n",
      "   +- *(2) Project [feature#731]\n",
      "      +- Filter ((isnotnull(pythonUDF0#789) AND isnotnull( **org.apache.spark.sql.sedona_sql.expressions.ST_MakeValid**  )) AND NOT  **org.apache.spark.sql.sedona_sql.expressions.ST_IsEmpty**  )\n",
      "         +- BatchEvalPython [fix_geom(feature#731.geometry)#746], [pythonUDF0#789]\n",
      "            +- *(1) Filter (((((isnotnull(feature#731.properties.POP20) AND isnotnull(feature#731.properties.HOUSING20)) AND isnotnull(trim(feature#731.properties.COMM, None))) AND NOT (trim(feature#731.properties.COMM, None) = )) AND isnotnull(cast(feature#731.properties.POP20 as double))) AND isnotnull(cast(feature#731.properties.HOUSING20 as double)))\n",
      "               +- *(1) Generate explode(features#697), false, [feature#731]\n",
      "                  +- *(1) Filter ((size(features#697, true) > 0) AND isnotnull(features#697))\n",
      "                     +- FileScan json [features#697] Batched: false, DataFilters: [(size(features#697, true) > 0), isnotnull(features#697)], Format: JSON, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_C..., PartitionFilters: [], PushedFilters: [IsNotNull(features)], ReadSchema: struct<features:array<struct<geometry:struct<coordinates:array<array<array<string>>>,type:string>...\n",
      ",None)\n",
      "\n",
      "(10) Scan json \n",
      "Output [1]: [features#697]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Census_Blocks_2020.geojson]\n",
      "PushedFilters: [IsNotNull(features)]\n",
      "ReadSchema: struct<features:array<struct<geometry:struct<coordinates:array<array<array<string>>>,type:string>,properties:struct<BG20:string,BG20FIP_CURRENT:string,BGFIP20:string,CB20:string,CITY:string,CITYCOMM:string,CITYCOMM_CURRENT:string,CITY_CURRENT:string,COMM:string,COMM_CURRENT:string,COUNTY:string,CT20:string,CTCB20:string,FEAT_TYPE:string,FIP20:string,FIP_CURRENT:string,HD22:bigint,HD_NAME:string,HOUSING20:bigint,OBJECTID:bigint,POP20:bigint,SPA22:bigint,SPA_NAME:string,SUP21:string,SUP_LABEL:string,ShapeSTArea:double,ShapeSTLength:double,State:string,ZCTA20:string>,type:string>>>\n",
      "\n",
      "(11) Filter [codegen id : 1]\n",
      "Input [1]: [features#697]\n",
      "Condition : ((size(features#697, true) > 0) AND isnotnull(features#697))\n",
      "\n",
      "(12) Generate [codegen id : 1]\n",
      "Input [1]: [features#697]\n",
      "Arguments: explode(features#697), false, [feature#731]\n",
      "\n",
      "(13) Filter [codegen id : 1]\n",
      "Input [1]: [feature#731]\n",
      "Condition : (((((isnotnull(feature#731.properties.POP20) AND isnotnull(feature#731.properties.HOUSING20)) AND isnotnull(trim(feature#731.properties.COMM, None))) AND NOT (trim(feature#731.properties.COMM, None) = )) AND isnotnull(cast(feature#731.properties.POP20 as double))) AND isnotnull(cast(feature#731.properties.HOUSING20 as double)))\n",
      "\n",
      "(14) BatchEvalPython\n",
      "Input [1]: [feature#731]\n",
      "Arguments: [fix_geom(feature#731.geometry)#746], [pythonUDF0#789]\n",
      "\n",
      "(15) Filter\n",
      "Input [2]: [feature#731, pythonUDF0#789]\n",
      "Condition : ((isnotnull(pythonUDF0#789) AND isnotnull( **org.apache.spark.sql.sedona_sql.expressions.ST_MakeValid**  )) AND NOT  **org.apache.spark.sql.sedona_sql.expressions.ST_IsEmpty**  )\n",
      "\n",
      "(16) Project [codegen id : 2]\n",
      "Output [1]: [feature#731]\n",
      "Input [2]: [feature#731, pythonUDF0#789]\n",
      "\n",
      "(17) BatchEvalPython\n",
      "Input [1]: [feature#731]\n",
      "Arguments: [fix_geom(feature#731.geometry)#746], [pythonUDF0#790]\n",
      "\n",
      "(18) Project\n",
      "Output [5]: [trim(feature#731.properties.COMM, None) AS COMM#778, feature#731.properties.ZCTA20 AS ZCTA20#765, cast(feature#731.properties.POP20 as double) AS POP20#766, cast(feature#731.properties.HOUSING20 as double) AS HOUSING20#767,  **org.apache.spark.sql.sedona_sql.expressions.ST_MakeValid**   AS geom#768]\n",
      "Input [2]: [feature#731, pythonUDF0#790]\n",
      "\n",
      "(19) Filter\n",
      "Input [2]: [COMM#778, geom#768]\n",
      "Condition : isnotnull(geom#768)\n",
      "\n",
      "(20) RangeJoin\n",
      "Arguments: crime_geom#537: geometry, geom#768: geometry, WITHIN\n",
      "\n",
      "(21) Project\n",
      "Output [3]: [crime_id#536, YEAR_OCC#244, COMM#778]\n",
      "Input [5]: [crime_id#536, YEAR_OCC#244, crime_geom#537, COMM#778, geom#768]\n",
      "\n",
      "(22) AdaptiveSparkPlan\n",
      "Output [3]: [crime_id#536, YEAR_OCC#244, COMM#778]\n",
      "Arguments: isFinalPlan=false\n",
      "\n",
      "\n",
      ">>> [timing] Explain spatial join took 1.37s\n",
      ">>> crimes_with_comm rows: 406475\n",
      ">>> [timing] Tie-break (count) took 26.96s\n",
      "+---------+--------+------------------+\n",
      "|crime_id |YEAR_OCC|COMM              |\n",
      "+---------+--------+------------------+\n",
      "|200100002|2020    |Wholesale District|\n",
      "|200100547|2020    |Downtown          |\n",
      "|200100550|2020    |Downtown          |\n",
      "|200100609|2020    |Downtown          |\n",
      "|200100632|2020    |Wholesale District|\n",
      "|200100745|2020    |Downtown          |\n",
      "|200100811|2020    |Downtown          |\n",
      "|200100812|2020    |Downtown          |\n",
      "|200100833|2020    |Wholesale District|\n",
      "|200100910|2020    |Downtown          |\n",
      "|200101018|2020    |Downtown          |\n",
      "|200101074|2020    |Downtown          |\n",
      "|200101125|2020    |Downtown          |\n",
      "|200104034|2020    |Downtown          |\n",
      "|200104036|2020    |Wholesale District|\n",
      "|200104039|2020    |Downtown          |\n",
      "|200104275|2020    |Downtown          |\n",
      "|200104417|2020    |Downtown          |\n",
      "|200104470|2020    |Little Tokyo      |\n",
      "|200104473|2020    |Downtown          |\n",
      "+---------+--------+------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "\n",
      "== Spark plan: After tie-break (row_number / filter rk==1) ==\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan (30)\n",
      "+- Project (29)\n",
      "   +- Filter (28)\n",
      "      +- Window (27)\n",
      "         +- WindowGroupLimit (26)\n",
      "            +- Sort (25)\n",
      "               +- Exchange (24)\n",
      "                  +- WindowGroupLimit (23)\n",
      "                     +- Sort (22)\n",
      "                        +- Project (21)\n",
      "                           +- RangeJoin (20)\n",
      "                              :- Union (7)\n",
      "                              :  :- Project (3)\n",
      "                              :  :  +- Filter (2)\n",
      "                              :  :     +- Scan csv  (1)\n",
      "                              :  +- Project (6)\n",
      "                              :     +- Filter (5)\n",
      "                              :        +- Scan csv  (4)\n",
      "                              +- Filter (19)\n",
      "                                 +- InMemoryTableScan (8)\n",
      "                                       +- InMemoryRelation (9)\n",
      "                                             +- Project (18)\n",
      "                                                +- BatchEvalPython (17)\n",
      "                                                   +- * Project (16)\n",
      "                                                      +- Filter (15)\n",
      "                                                         +- BatchEvalPython (14)\n",
      "                                                            +- * Filter (13)\n",
      "                                                               +- * Generate (12)\n",
      "                                                                  +- * Filter (11)\n",
      "                                                                     +- Scan json  (10)\n",
      "\n",
      "\n",
      "(1) Scan csv \n",
      "Output [4]: [DR_NO#42, DATE OCC#44, LAT#68, LON#69]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Crime_Data/LA_Crime_Data_2010_2019.csv]\n",
      "PushedFilters: [IsNotNull(LAT), IsNotNull(LON)]\n",
      "ReadSchema: struct<DR_NO:string,DATE OCC:string,LAT:string,LON:string>\n",
      "\n",
      "(2) Filter\n",
      "Input [4]: [DR_NO#42, DATE OCC#44, LAT#68, LON#69]\n",
      "Condition : (((((((isnotnull(LAT#68) AND isnotnull(LON#69)) AND (year(cast(gettimestamp(DATE OCC#44, yyyy MMM dd hh:mm:ss a, TimestampType, Some(UTC), false) as date)) >= 2020)) AND (year(cast(gettimestamp(DATE OCC#44, yyyy MMM dd hh:mm:ss a, TimestampType, Some(UTC), false) as date)) <= 2021)) AND isnotnull(cast(LAT#68 as double))) AND isnotnull(cast(LON#69 as double))) AND (NOT (cast(LAT#68 as double) = 0.0) OR NOT (cast(LON#69 as double) = 0.0))) AND isnotnull( **org.apache.spark.sql.sedona_sql.expressions.ST_Point**  ))\n",
      "\n",
      "(3) Project\n",
      "Output [3]: [DR_NO#42 AS crime_id#536, year(cast(gettimestamp(DATE OCC#44, yyyy MMM dd hh:mm:ss a, TimestampType, Some(UTC), false) as date)) AS YEAR_OCC#244,  **org.apache.spark.sql.sedona_sql.expressions.ST_Point**   AS crime_geom#537]\n",
      "Input [4]: [DR_NO#42, DATE OCC#44, LAT#68, LON#69]\n",
      "\n",
      "(4) Scan csv \n",
      "Output [4]: [DR_NO#116, DATE OCC#118, LAT#142, LON#143]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Crime_Data/LA_Crime_Data_2020_2025.csv]\n",
      "PushedFilters: [IsNotNull(LAT), IsNotNull(LON)]\n",
      "ReadSchema: struct<DR_NO:string,DATE OCC:string,LAT:string,LON:string>\n",
      "\n",
      "(5) Filter\n",
      "Input [4]: [DR_NO#116, DATE OCC#118, LAT#142, LON#143]\n",
      "Condition : (((((((isnotnull(LAT#142) AND isnotnull(LON#143)) AND (year(cast(gettimestamp(DATE OCC#118, yyyy MMM dd hh:mm:ss a, TimestampType, Some(UTC), false) as date)) >= 2020)) AND (year(cast(gettimestamp(DATE OCC#118, yyyy MMM dd hh:mm:ss a, TimestampType, Some(UTC), false) as date)) <= 2021)) AND isnotnull(cast(LAT#142 as double))) AND isnotnull(cast(LON#143 as double))) AND (NOT (cast(LAT#142 as double) = 0.0) OR NOT (cast(LON#143 as double) = 0.0))) AND isnotnull( **org.apache.spark.sql.sedona_sql.expressions.ST_Point**  ))\n",
      "\n",
      "(6) Project\n",
      "Output [3]: [DR_NO#116 AS crime_id#2724, year(cast(gettimestamp(DATE OCC#118, yyyy MMM dd hh:mm:ss a, TimestampType, Some(UTC), false) as date)) AS YEAR_OCC#2721,  **org.apache.spark.sql.sedona_sql.expressions.ST_Point**   AS crime_geom#2725]\n",
      "Input [4]: [DR_NO#116, DATE OCC#118, LAT#142, LON#143]\n",
      "\n",
      "(7) Union\n",
      "\n",
      "(8) InMemoryTableScan\n",
      "Output [2]: [COMM#778, geom#768]\n",
      "Arguments: [COMM#778, geom#768], [isnotnull(geom#768)]\n",
      "\n",
      "(9) InMemoryRelation\n",
      "Arguments: [COMM#778, ZCTA20#765, POP20#766, HOUSING20#767, geom#768], CachedRDDBuilder(org.apache.spark.sql.execution.columnar.DefaultCachedBatchSerializer@a8621de,StorageLevel(disk, memory, deserialized, 1 replicas),Project [trim(feature#731.properties.COMM, None) AS COMM#778, feature#731.properties.ZCTA20 AS ZCTA20#765, cast(feature#731.properties.POP20 as double) AS POP20#766, cast(feature#731.properties.HOUSING20 as double) AS HOUSING20#767,  **org.apache.spark.sql.sedona_sql.expressions.ST_MakeValid**   AS geom#768]\n",
      "+- BatchEvalPython [fix_geom(feature#731.geometry)#746], [pythonUDF0#790]\n",
      "   +- *(2) Project [feature#731]\n",
      "      +- Filter ((isnotnull(pythonUDF0#789) AND isnotnull( **org.apache.spark.sql.sedona_sql.expressions.ST_MakeValid**  )) AND NOT  **org.apache.spark.sql.sedona_sql.expressions.ST_IsEmpty**  )\n",
      "         +- BatchEvalPython [fix_geom(feature#731.geometry)#746], [pythonUDF0#789]\n",
      "            +- *(1) Filter (((((isnotnull(feature#731.properties.POP20) AND isnotnull(feature#731.properties.HOUSING20)) AND isnotnull(trim(feature#731.properties.COMM, None))) AND NOT (trim(feature#731.properties.COMM, None) = )) AND isnotnull(cast(feature#731.properties.POP20 as double))) AND isnotnull(cast(feature#731.properties.HOUSING20 as double)))\n",
      "               +- *(1) Generate explode(features#697), false, [feature#731]\n",
      "                  +- *(1) Filter ((size(features#697, true) > 0) AND isnotnull(features#697))\n",
      "                     +- FileScan json [features#697] Batched: false, DataFilters: [(size(features#697, true) > 0), isnotnull(features#697)], Format: JSON, Location: InMemoryFileIndex(1 paths)[s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_C..., PartitionFilters: [], PushedFilters: [IsNotNull(features)], ReadSchema: struct<features:array<struct<geometry:struct<coordinates:array<array<array<string>>>,type:string>...\n",
      ",None)\n",
      "\n",
      "(10) Scan json \n",
      "Output [1]: [features#697]\n",
      "Batched: false\n",
      "Location: InMemoryFileIndex [s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Census_Blocks_2020.geojson]\n",
      "PushedFilters: [IsNotNull(features)]\n",
      "ReadSchema: struct<features:array<struct<geometry:struct<coordinates:array<array<array<string>>>,type:string>,properties:struct<BG20:string,BG20FIP_CURRENT:string,BGFIP20:string,CB20:string,CITY:string,CITYCOMM:string,CITYCOMM_CURRENT:string,CITY_CURRENT:string,COMM:string,COMM_CURRENT:string,COUNTY:string,CT20:string,CTCB20:string,FEAT_TYPE:string,FIP20:string,FIP_CURRENT:string,HD22:bigint,HD_NAME:string,HOUSING20:bigint,OBJECTID:bigint,POP20:bigint,SPA22:bigint,SPA_NAME:string,SUP21:string,SUP_LABEL:string,ShapeSTArea:double,ShapeSTLength:double,State:string,ZCTA20:string>,type:string>>>\n",
      "\n",
      "(11) Filter [codegen id : 1]\n",
      "Input [1]: [features#697]\n",
      "Condition : ((size(features#697, true) > 0) AND isnotnull(features#697))\n",
      "\n",
      "(12) Generate [codegen id : 1]\n",
      "Input [1]: [features#697]\n",
      "Arguments: explode(features#697), false, [feature#731]\n",
      "\n",
      "(13) Filter [codegen id : 1]\n",
      "Input [1]: [feature#731]\n",
      "Condition : (((((isnotnull(feature#731.properties.POP20) AND isnotnull(feature#731.properties.HOUSING20)) AND isnotnull(trim(feature#731.properties.COMM, None))) AND NOT (trim(feature#731.properties.COMM, None) = )) AND isnotnull(cast(feature#731.properties.POP20 as double))) AND isnotnull(cast(feature#731.properties.HOUSING20 as double)))\n",
      "\n",
      "(14) BatchEvalPython\n",
      "Input [1]: [feature#731]\n",
      "Arguments: [fix_geom(feature#731.geometry)#746], [pythonUDF0#789]\n",
      "\n",
      "(15) Filter\n",
      "Input [2]: [feature#731, pythonUDF0#789]\n",
      "Condition : ((isnotnull(pythonUDF0#789) AND isnotnull( **org.apache.spark.sql.sedona_sql.expressions.ST_MakeValid**  )) AND NOT  **org.apache.spark.sql.sedona_sql.expressions.ST_IsEmpty**  )\n",
      "\n",
      "(16) Project [codegen id : 2]\n",
      "Output [1]: [feature#731]\n",
      "Input [2]: [feature#731, pythonUDF0#789]\n",
      "\n",
      "(17) BatchEvalPython\n",
      "Input [1]: [feature#731]\n",
      "Arguments: [fix_geom(feature#731.geometry)#746], [pythonUDF0#790]\n",
      "\n",
      "(18) Project\n",
      "Output [5]: [trim(feature#731.properties.COMM, None) AS COMM#778, feature#731.properties.ZCTA20 AS ZCTA20#765, cast(feature#731.properties.POP20 as double) AS POP20#766, cast(feature#731.properties.HOUSING20 as double) AS HOUSING20#767,  **org.apache.spark.sql.sedona_sql.expressions.ST_MakeValid**   AS geom#768]\n",
      "Input [2]: [feature#731, pythonUDF0#790]\n",
      "\n",
      "(19) Filter\n",
      "Input [2]: [COMM#778, geom#768]\n",
      "Condition : isnotnull(geom#768)\n",
      "\n",
      "(20) RangeJoin\n",
      "Arguments: crime_geom#537: geometry, geom#768: geometry, WITHIN\n",
      "\n",
      "(21) Project\n",
      "Output [3]: [crime_id#536, YEAR_OCC#244, COMM#778]\n",
      "Input [5]: [crime_id#536, YEAR_OCC#244, crime_geom#537, COMM#778, geom#768]\n",
      "\n",
      "(22) Sort\n",
      "Input [3]: [crime_id#536, YEAR_OCC#244, COMM#778]\n",
      "Arguments: [crime_id#536 ASC NULLS FIRST, COMM#778 ASC NULLS FIRST], false, 0\n",
      "\n",
      "(23) WindowGroupLimit\n",
      "Input [3]: [crime_id#536, YEAR_OCC#244, COMM#778]\n",
      "Arguments: [crime_id#536], [COMM#778 ASC NULLS FIRST], row_number(), 1, Partial\n",
      "\n",
      "(24) Exchange\n",
      "Input [3]: [crime_id#536, YEAR_OCC#244, COMM#778]\n",
      "Arguments: hashpartitioning(crime_id#536, 1000), ENSURE_REQUIREMENTS, [plan_id=2352]\n",
      "\n",
      "(25) Sort\n",
      "Input [3]: [crime_id#536, YEAR_OCC#244, COMM#778]\n",
      "Arguments: [crime_id#536 ASC NULLS FIRST, COMM#778 ASC NULLS FIRST], false, 0\n",
      "\n",
      "(26) WindowGroupLimit\n",
      "Input [3]: [crime_id#536, YEAR_OCC#244, COMM#778]\n",
      "Arguments: [crime_id#536], [COMM#778 ASC NULLS FIRST], row_number(), 1, Final\n",
      "\n",
      "(27) Window\n",
      "Input [3]: [crime_id#536, YEAR_OCC#244, COMM#778]\n",
      "Arguments: [row_number() windowspecdefinition(crime_id#536, COMM#778 ASC NULLS FIRST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS rk#2342], [crime_id#536], [COMM#778 ASC NULLS FIRST]\n",
      "\n",
      "(28) Filter\n",
      "Input [4]: [crime_id#536, YEAR_OCC#244, COMM#778, rk#2342]\n",
      "Condition : (rk#2342 = 1)\n",
      "\n",
      "(29) Project\n",
      "Output [3]: [crime_id#536, YEAR_OCC#244, COMM#778]\n",
      "Input [4]: [crime_id#536, YEAR_OCC#244, COMM#778, rk#2342]\n",
      "\n",
      "(30) AdaptiveSparkPlan\n",
      "Output [3]: [crime_id#536, YEAR_OCC#244, COMM#778]\n",
      "Arguments: isFinalPlan=false\n",
      "\n",
      "\n",
      ">>> [timing] Explain tie-break took 19.89s\n",
      ">>> crime_counts_by_comm rows: 154\n",
      ">>> [timing] Crime counts per COMM (count) took 7.38s\n",
      "+------------------+---------------------+\n",
      "|COMM              |crime_count_2020_2021|\n",
      "+------------------+---------------------+\n",
      "|Downtown          |14844                |\n",
      "|North Hollywood   |14160                |\n",
      "|Hollywood         |14033                |\n",
      "|Wholesale District|11695                |\n",
      "|Melrose           |9622                 |\n",
      "|Van Nuys          |9475                 |\n",
      "|Sherman Oaks      |8214                 |\n",
      "|Boyle Heights     |8087                 |\n",
      "|Westlake          |7607                 |\n",
      "|Westchester       |7592                 |\n",
      "|San Pedro         |7219                 |\n",
      "|Vermont Vista     |6837                 |\n",
      "|West Vernon       |6621                 |\n",
      "|Florence-Firestone|6408                 |\n",
      "|Venice            |6306                 |\n",
      "|Northridge        |6217                 |\n",
      "|Canoga Park       |6200                 |\n",
      "|Harvard Park      |6130                 |\n",
      "|Woodland Hills    |5692                 |\n",
      "|Reseda            |5636                 |\n",
      "+------------------+---------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      ">>> area_stats rows: 255\n",
      ">>> [timing] Join area_stats (count) took 6.62s\n",
      "+--------------------------------------+------------------+---------+---------------------+\n",
      "|COMM                                  |per_capita_income |total_pop|crime_count_2020_2021|\n",
      "+--------------------------------------+------------------+---------+---------------------+\n",
      "|Franklin Canyon                       |154740.0          |1.0      |0                    |\n",
      "|Palos Verdes Peninsula                |100709.34075104311|719.0    |0                    |\n",
      "|Marina del Rey                        |97983.0745900194  |11342.0  |67                   |\n",
      "|Pacific Palisades                     |87750.52529591447 |20952.0  |1362                 |\n",
      "|Marina Peninsula                      |85588.53457067102 |4903.0   |475                  |\n",
      "|Palisades Highlands                   |83576.88954231654 |3911.0   |127                  |\n",
      "|Playa Vista                           |81679.88040665434 |16230.0  |1294                 |\n",
      "|Bel Air                               |80412.74199793495 |7748.0   |528                  |\n",
      "|Santa Catalina Island                 |74903.62352941177 |255.0    |0                    |\n",
      "|Brentwood                             |72946.3541900178  |30334.0  |2144                 |\n",
      "|Beverly Crest                         |69669.54254069475 |11918.0  |616                  |\n",
      "|Westfield/Academy Hills               |68003.89684813753 |1396.0   |0                    |\n",
      "|Mandeville Canyon                     |65870.0709438618  |3242.0   |103                  |\n",
      "|Venice                                |63440.7489833752  |33444.0  |6306                 |\n",
      "|Carthay                               |62780.30752840909 |14080.0  |2104                 |\n",
      "|Bouquet Canyon                        |60732.07149321267 |1105.0   |0                    |\n",
      "|San Francisquito Canyon/Bouquet Canyon|60634.46153846154 |325.0    |0                    |\n",
      "|Playa Del Rey                         |60390.17038539554 |2958.0   |378                  |\n",
      "|Century City                          |58903.81757352941 |13600.0  |1376                 |\n",
      "|Padua Hills                           |58891.90476190476 |126.0    |0                    |\n",
      "|Studio City                           |56739.51027412525 |22435.0  |2570                 |\n",
      "|Rancho Park                           |55901.236980339185|6663.0   |990                  |\n",
      "|West Los Angeles                      |55240.442636462736|37611.0  |4474                 |\n",
      "|Santa Monica Mountains                |54269.08820490511 |18389.0  |1                    |\n",
      "|Westchester                           |52322.510776201736|50760.0  |7592                 |\n",
      "|Hollywood Hills                       |51724.91869672159 |29679.0  |3293                 |\n",
      "|San Pasqual                           |51684.05854355069 |2101.0   |0                    |\n",
      "|South Carthay                         |51376.677012048196|10375.0  |1055                 |\n",
      "|Agua Dulce                            |50990.591990291265|4120.0   |0                    |\n",
      "|Stevenson Ranch                       |50687.118466234264|20968.0  |0                    |\n",
      "+--------------------------------------+------------------+---------+---------------------+\n",
      "only showing top 30 rows\n",
      "\n",
      ">>> area_stats with avg_annual_crime_per_person (sample):\n",
      "+-----------------------+------------------+---------------------+---------------------------+---------+---------------------+\n",
      "|COMM                   |per_capita_income |crime_per_1k_per_year|avg_annual_crime_per_person|total_pop|crime_count_2020_2021|\n",
      "+-----------------------+------------------+---------------------+---------------------------+---------+---------------------+\n",
      "|Acton                  |43238.85842523724 |0.0                  |0.0                        |7798.0   |0                    |\n",
      "|Adams-Normandie        |14800.065217391304|50.13175230566535    |0.05013175230566535        |7590.0   |761                  |\n",
      "|Agua Dulce             |50990.591990291265|0.0                  |0.0                        |4120.0   |0                    |\n",
      "|Alsace                 |17898.197668909314|44.347578887520136   |0.04434757888752014        |10553.0  |936                  |\n",
      "|Altadena               |41222.94071791999 |0.0                  |0.0                        |42846.0  |0                    |\n",
      "|Anaverde               |29706.45984363895 |0.0                  |0.0                        |1407.0   |0                    |\n",
      "|Angeles National Forest|29002.603417266186|16.636690647482013   |0.016636690647482015       |1112.0   |37                   |\n",
      "|Angelino Heights       |31017.07939119704 |51.21349238996298    |0.05121349238996298        |2431.0   |249                  |\n",
      "|Arcadia                |38758.50407263987 |0.0                  |0.0                        |7489.0   |0                    |\n",
      "|Arleta                 |17205.06464325441 |24.980136659780708   |0.02498013665978071        |31465.0  |1572                 |\n",
      "|Athens Village         |12388.902329075883|0.0                  |0.0                        |5324.0   |0                    |\n",
      "|Athens-Westmont        |16144.347411444141|1.3508520759248142   |0.0013508520759248142      |43306.0  |117                  |\n",
      "|Atwater Village        |41900.43990301351 |44.821614132317286   |0.044821614132317285       |14435.0  |1294                 |\n",
      "|Avocado Heights        |19639.269938650308|0.0                  |0.0                        |6520.0   |0                    |\n",
      "|Azusa                  |18962.07440758294 |0.0                  |0.0                        |14770.0  |0                    |\n",
      "|Baldwin Hills          |23104.693580542265|63.91214779372674    |0.06391214779372674        |30096.0  |3847                 |\n",
      "|Bandini Islands        |NULL              |NULL                 |NULL                       |0.0      |0                    |\n",
      "|Bassett                |18772.887363629794|0.0                  |0.0                        |13841.0  |0                    |\n",
      "|Bel Air                |80412.74199793495 |34.07330924109448    |0.034073309241094474       |7748.0   |528                  |\n",
      "|Beverly Crest          |69669.54254069475 |25.843262292330927   |0.02584326229233093        |11918.0  |616                  |\n",
      "|Beverlywood            |40121.1514450867  |39.34489402697495    |0.03934489402697495        |12975.0  |1021                 |\n",
      "|Bouquet Canyon         |60732.07149321267 |0.0                  |0.0                        |1105.0   |0                    |\n",
      "|Boyle Heights          |14566.388579351753|51.43616750623315    |0.051436167506233144       |78612.0  |8087                 |\n",
      "|Bradbury               |33488.07580174927 |0.0                  |0.0                        |343.0    |0                    |\n",
      "|Brentwood              |72946.3541900178  |35.339882639941976   |0.03533988263994198        |30334.0  |2144                 |\n",
      "|Brookside              |20404.608333333334|38.888888888888886   |0.03888888888888889        |720.0    |56                   |\n",
      "|Cadillac-Corning       |33043.29116003944 |38.61321064738745    |0.038613210647387444       |6086.0   |470                  |\n",
      "|Canoga Park            |25912.139668194228|49.49941718428154    |0.04949941718428154        |62627.0  |6200                 |\n",
      "|Canyon Country         |33370.972389558236|0.0                  |0.0                        |1992.0   |0                    |\n",
      "|Carthay                |62780.30752840909 |74.7159090909091     |0.0747159090909091         |14080.0  |2104                 |\n",
      "+-----------------------+------------------+---------------------+---------------------------+---------+---------------------+\n",
      "only showing top 30 rows\n",
      "\n",
      ">>> [timing] Compute KPIs (show) took 13.62s\n",
      "Overall correlation (all COMM): -0.07527250172607444\n",
      ">>> [timing] Overall correlation took 1.23s\n",
      "Overall correlation (all COMM) [Spearman]: -0.08552188481024518\n",
      ">>> top10 rows: 10\n",
      ">>> bottom10 rows: 10\n",
      ">>> [timing] Top/Bottom selection (counts) took 8.81s\n",
      "Correlation (Top-10 richest COMM): -0.5026546277193615\n",
      "Correlation (Bottom-10 poorest COMM): 0.6868818922801208\n",
      ">>> [timing] Top/Bottom correlations took 1.82s\n",
      "Correlation (Top-10 richest COMM) [Spearman]: -0.4478864769720896\n",
      "Correlation (Bottom-10 poorest COMM) [Spearman]: 0.7463786160872516\n",
      "\n",
      "Top-10 COMM by per_capita_income:\n",
      "+----------------------+------------------+---------------------+---------------------------+---------+---------------------+\n",
      "|COMM                  |per_capita_income |crime_per_1k_per_year|avg_annual_crime_per_person|total_pop|crime_count_2020_2021|\n",
      "+----------------------+------------------+---------------------+---------------------------+---------+---------------------+\n",
      "|Franklin Canyon       |154740.0          |0.0                  |0.0                        |1.0      |0                    |\n",
      "|Palos Verdes Peninsula|100709.34075104311|0.0                  |0.0                        |719.0    |0                    |\n",
      "|Marina del Rey        |97983.0745900194  |2.9536236995238934   |0.0029536236995238935      |11342.0  |67                   |\n",
      "|Pacific Palisades     |87750.52529591447 |32.5028636884307     |0.0325028636884307         |20952.0  |1362                 |\n",
      "|Marina Peninsula      |85588.53457067102 |48.43973077707526    |0.04843973077707526        |4903.0   |475                  |\n",
      "|Palisades Highlands   |83576.88954231654 |16.236256711838404   |0.016236256711838405       |3911.0   |127                  |\n",
      "|Playa Vista           |81679.88040665434 |39.864448552064076   |0.03986444855206408        |16230.0  |1294                 |\n",
      "|Bel Air               |80412.74199793495 |34.07330924109448    |0.034073309241094474       |7748.0   |528                  |\n",
      "|Santa Catalina Island |74903.62352941177 |0.0                  |0.0                        |255.0    |0                    |\n",
      "|Brentwood             |72946.3541900178  |35.339882639941976   |0.03533988263994198        |30334.0  |2144                 |\n",
      "+----------------------+------------------+---------------------+---------------------------+---------+---------------------+\n",
      "\n",
      "\n",
      "Bottom-10 COMM by per_capita_income:\n",
      "+----------------+------------------+---------------------+---------------------------+---------+---------------------+\n",
      "|COMM            |per_capita_income |crime_per_1k_per_year|avg_annual_crime_per_person|total_pop|crime_count_2020_2021|\n",
      "+----------------+------------------+---------------------+---------------------------+---------+---------------------+\n",
      "|Lynwood         |0.0               |0.0                  |0.0                        |6.0      |0                    |\n",
      "|Lakewood        |0.0               |0.0                  |0.0                        |117.0    |0                    |\n",
      "|West LA         |4297.9052013422815|56.20805369127517    |0.05620805369127517        |1192.0   |134                  |\n",
      "|Pomona          |6572.923898071625 |0.0                  |0.0                        |2904.0   |0                    |\n",
      "|Whittier Narrows|8708.333333333334 |0.0                  |0.0                        |75.0     |0                    |\n",
      "|Vernon Central  |10950.147886890725|45.02019808477044    |0.04502019808477044        |48767.0  |4391                 |\n",
      "|South Park      |11413.401021995112|54.72395023328149    |0.05472395023328149        |36008.0  |3941                 |\n",
      "|Central         |11541.450975876562|49.283205711324776   |0.04928320571132477        |34738.0  |3424                 |\n",
      "|Watts           |11751.343251432088|56.5970742792217     |0.0565970742792217         |42246.0  |4782                 |\n",
      "|Green Meadows   |11848.86150789897 |75.41859805127235    |0.07541859805127235        |21142.0  |3189                 |\n",
      "+----------------+------------------+---------------------+---------------------------+---------+---------------------+\n",
      "\n",
      ">>> [timing] Final shows took 2.87s\n",
      "\n",
      ">>> [timing] TOTAL EXECUTION TIME: 205.04s"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StringType\n",
    "from pyspark.sql import Window\n",
    "from sedona.register import SedonaRegistrator\n",
    "import json\n",
    "import time\n",
    "\n",
    "# --- Timing helpers ---\n",
    "SHOW_STEP_TIMES = True\n",
    "_T0 = time.time()\n",
    "_tprev = _T0\n",
    "def _lap(label):\n",
    "    global _tprev\n",
    "    if SHOW_STEP_TIMES:\n",
    "        dt = time.time() - _tprev\n",
    "        print(f\">>> [timing] {label} took {dt:.2f}s\")\n",
    "    _tprev = time.time()\n",
    "\n",
    "SedonaRegistrator.registerAll(spark)\n",
    "print(\">>> Sedona registered OK\")\n",
    "\n",
    "\n",
    "POINT_ORDER = \"lonlat\"       # \"lonlat\" (x=lon,y=lat) ή \"latlon\"\n",
    "SPATIAL_JOIN = \"contains\"    # 'contains' / 'covers' / 'intersects'\n",
    "\n",
    "crime_2010_2019_path = \"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Crime_Data/LA_Crime_Data_2010_2019.csv\"\n",
    "crime_2020_plus_path = \"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Crime_Data/LA_Crime_Data_2020_2025.csv\"\n",
    "census_geojson_path  = \"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_Census_Blocks_2020.geojson\"\n",
    "income_path          = \"s3://initial-notebook-data-bucket-dblab-905418150721/project_data/LA_income_2021.csv\"\n",
    "\n",
    "crimes_2010_2019 = spark.read.option(\"header\", True).csv(crime_2010_2019_path)\n",
    "crimes_2020_plus = spark.read.option(\"header\", True).csv(crime_2020_plus_path)\n",
    "crimes = crimes_2010_2019.unionByName(crimes_2020_plus)\n",
    "\n",
    "print(\">>> crimes total rows:\", crimes.count()); _lap(\"Load & union crimes (count)\")\n",
    "print(\">>> crimes schema:\")\n",
    "crimes.printSchema()\n",
    "\n",
    "crimes = crimes.select(\"DR_NO\", \"DATE OCC\", \"LAT\", \"LON\")\n",
    "print(\">>> crimes selected cols schema:\")\n",
    "crimes.printSchema()\n",
    "\n",
    "crimes = crimes.withColumn(\"DATE_OCC_TS\", F.to_timestamp(\"DATE OCC\", \"yyyy MMM dd hh:mm:ss a\")) \\\n",
    "               .withColumn(\"YEAR_OCC\", F.year(\"DATE_OCC_TS\"))\n",
    "\n",
    "print(\">>> crimes with YEAR_OCC sample:\")\n",
    "crimes.select(\"DR_NO\", \"DATE OCC\", \"DATE_OCC_TS\", \"YEAR_OCC\").show(10, truncate=False); _lap(\"Derive YEAR_OCC (show)\")\n",
    "\n",
    "# 2020–2021\n",
    "crimes_2020_2021 = crimes.filter((F.col(\"YEAR_OCC\") >= 2020) & (F.col(\"YEAR_OCC\") <= 2021))\n",
    "print(\">>> crimes_2020_2021 rows after year filter:\", crimes_2020_2021.count()); _lap(\"Filter 2020–2021 (count)\")\n",
    "\n",
    "# LAT/LON σε double + φίλτρα 0/Null\n",
    "crimes_2020_2021 = (crimes_2020_2021\n",
    "    .withColumn(\"LAT_D\", F.col(\"LAT\").cast(\"double\"))\n",
    "    .withColumn(\"LON_D\", F.col(\"LON\").cast(\"double\"))\n",
    "    .filter(F.col(\"LAT_D\").isNotNull() & F.col(\"LON_D\").isNotNull())\n",
    "    .filter(~((F.col(\"LAT_D\") == 0.0) & (F.col(\"LON_D\") == 0.0)))\n",
    ")\n",
    "\n",
    "print(\">>> crimes_2020_2021 rows after coord filters:\", crimes_2020_2021.count())\n",
    "crimes_2020_2021.select(\"DR_NO\", \"YEAR_OCC\", \"LAT_D\", \"LON_D\").show(10, truncate=False); _lap(\"Clean coords (count+show)\")\n",
    "\n",
    "# Γεωμετρία εγκλημάτων (σημεία)\n",
    "if POINT_ORDER == \"latlon\":\n",
    "    crimes_geom = crimes_2020_2021.selectExpr(\n",
    "        \"DR_NO as crime_id\", \"YEAR_OCC\", \"ST_Point(LAT_D, LON_D) as crime_geom\"\n",
    "    )\n",
    "else:\n",
    "    crimes_geom = crimes_2020_2021.selectExpr(\n",
    "        \"DR_NO as crime_id\", \"YEAR_OCC\", \"ST_Point(LON_D, LAT_D) as crime_geom\"\n",
    "    )\n",
    "\n",
    "print(\">>> crimes_geom rows:\", crimes_geom.count())\n",
    "crimes_geom.show(5, truncate=False); _lap(\"Build crimes_geom (count+show)\")\n",
    "crimes_geom.createOrReplaceTempView(\"crimes_geom\")\n",
    "\n",
    "# Create Blocks\n",
    "blocks_raw = spark.read.option(\"multiline\", \"true\").json(census_geojson_path)\n",
    "print(\">>> blocks_raw schema:\")\n",
    "blocks_raw.printSchema()\n",
    "blocks_raw.select(\"crs\",\"features\",\"name\",\"type\").show(1, truncate=True)\n",
    "\n",
    "blocks_features = blocks_raw.selectExpr(\"explode(features) as feature\")\n",
    "print(\">>> blocks_features rows:\", blocks_features.count()); _lap(\"Read census geojson (count)\")\n",
    "\n",
    "# GeoJson Cleaning for Sedona\n",
    "\n",
    "# Coordinate Cleaning - Target [x,y]\n",
    "def _parse_pos(v):\n",
    "    \"\"\"Return [x,y] or None from: \"[x,y]\" | [\"x\",\"y\"] | [x,y].\"\"\"\n",
    "    if v is None:\n",
    "        return None\n",
    "    if isinstance(v, str): # if string coords\n",
    "        t = v.strip()\n",
    "        if t.startswith(\"[\") and t.endswith(\"]\"): t = t[1:-1]\n",
    "        parts = [p.strip() for p in t.split(\",\")]\n",
    "        if len(parts) >= 2:\n",
    "            try: return [float(parts[0]), float(parts[1])] # make float\n",
    "            except: return None\n",
    "        return None\n",
    "    if isinstance(v, (list, tuple)) and len(v) >= 2: # if list or tuple coords\n",
    "        try:\n",
    "            x = float(v[0]) if isinstance(v[0], (int, float, str)) else None # Return if\n",
    "            y = float(v[1]) if isinstance(v[1], (int, float, str)) else None # both are numbers\n",
    "            return [x, y] if x is not None and y is not None else None\n",
    "        except: return None\n",
    "    return None\n",
    "\n",
    "# In case of incomplete ring -> First point is also last\n",
    "def _close_ring_if_needed(r):\n",
    "    return r if (len(r) >= 4 and r[0] == r[-1]) else (r + [r[0]] if len(r) >= 3 else r)\n",
    "\n",
    "# Keep valid(parsable) points per ring\n",
    "def _clean_polygon_coords(rings):\n",
    "    if not isinstance(rings, (list, tuple)):\n",
    "        return None\n",
    "    cleaned_rings = []\n",
    "    for ring in rings:\n",
    "        if not isinstance(ring, (list, tuple)): continue\n",
    "        pts = [_parse_pos(pos) for pos in ring]\n",
    "        pts = [p for p in pts if p is not None]\n",
    "        if len(pts) >= 3:\n",
    "            pts = _close_ring_if_needed(pts)\n",
    "            if len(pts) >= 4:\n",
    "                cleaned_rings.append(pts)\n",
    "    return cleaned_rings if cleaned_rings else None\n",
    "\n",
    "def _clean_coords(gtype, coords):\n",
    "    if gtype == \"Polygon\":\n",
    "        return _clean_polygon_coords(coords)\n",
    "    if gtype == \"MultiPolygon\": # List of Rings\n",
    "        if not isinstance(coords, (list, tuple)): return None\n",
    "        polys = []\n",
    "        for poly in coords:\n",
    "            cr = _clean_polygon_coords(poly)\n",
    "            if cr is not None: polys.append(cr)\n",
    "        return polys if polys else None\n",
    "    return None\n",
    "\n",
    "def fix_geom(geom):\n",
    "    if geom is None: return None\n",
    "    gtype  = (geom.get(\"type\") if isinstance(geom, dict) else geom[\"type\"])\n",
    "    coords = (geom.get(\"coordinates\") if isinstance(geom, dict) else geom[\"coordinates\"])\n",
    "    cleaned = _clean_coords(gtype, coords)\n",
    "    if cleaned is None: return None\n",
    "    return json.dumps({\"type\": gtype, \"coordinates\": cleaned})\n",
    "\n",
    "fix_geom_udf = F.udf(fix_geom, StringType())\n",
    "\n",
    "blocks_with_geom_json = (blocks_features\n",
    "    .withColumn(\"geom_json_str\", fix_geom_udf(F.col(\"feature.geometry\")))\n",
    "    .filter(F.col(\"geom_json_str\").isNotNull())\n",
    ")\n",
    "\n",
    "print(\">>> sample geom_json_str (fixed):\")\n",
    "blocks_with_geom_json.select(\"geom_json_str\").show(3, truncate=True)\n",
    "\n",
    "blocks = (\n",
    "    blocks_with_geom_json\n",
    "    .select(\n",
    "        F.col(\"feature.properties.COMM\").alias(\"COMM\"),\n",
    "        F.col(\"feature.properties.ZCTA20\").cast(\"string\").alias(\"ZCTA20\"),\n",
    "        F.col(\"feature.properties.POP20\").cast(\"double\").alias(\"POP20\"),\n",
    "        F.col(\"feature.properties.HOUSING20\").cast(\"double\").alias(\"HOUSING20\"),\n",
    "        F.expr(\"ST_MakeValid(ST_GeomFromGeoJSON(geom_json_str))\").alias(\"geom\")\n",
    "    )\n",
    "    .withColumn(\"COMM\", F.trim(F.col(\"COMM\")))\n",
    "    .filter(F.col(\"COMM\").isNotNull() & (F.col(\"COMM\") != \"\"))\n",
    "    .filter(F.col(\"POP20\").isNotNull() & F.col(\"HOUSING20\").isNotNull())\n",
    "    .filter(F.col(\"geom\").isNotNull())\n",
    "    .filter(~F.expr(\"ST_IsEmpty(geom)\"))\n",
    ").cache()\n",
    "\n",
    "print(\">>> blocks rows after filters:\", blocks.count()); _lap(\"Build blocks (count)\")\n",
    "blocks.printSchema()\n",
    "blocks.createOrReplaceTempView(\"blocks_geom\")\n",
    "\n",
    "# QC\n",
    "blocks.selectExpr(\"ST_IsValid(geom) AS is_valid\",\"ST_IsEmpty(geom) AS is_empty\") \\\n",
    "      .groupBy(\"is_valid\",\"is_empty\").count().show(); _lap(\"QC blocks (show)\")\n",
    "\n",
    "# Per ZIP Income\n",
    "income_raw = (spark.read\n",
    "    .option(\"header\", True)\n",
    "    .option(\"delimiter\", \";\")\n",
    "    .csv(income_path)\n",
    ")\n",
    "\n",
    "print(\">>> income schema (raw):\")\n",
    "income_raw.printSchema()\n",
    "income_raw.show(10, truncate=False)\n",
    "\n",
    "income = (income_raw\n",
    "    .select(\n",
    "        F.trim(F.col(\"Zip Code\")).alias(\"ZIP\"),\n",
    "        F.col(\"Community\").alias(\"Community_name\"),\n",
    "        F.col(\"Estimated Median Income\").alias(\"EstimatedMedianIncome_raw\")\n",
    "    )\n",
    "    .withColumn(\"median_income_household\",\n",
    "        F.regexp_replace(\"EstimatedMedianIncome_raw\", \"[$,]\", \"\").cast(\"double\")\n",
    "    )\n",
    "    .filter(F.col(\"median_income_household\").isNotNull())\n",
    "    .withColumn(\"ZIP_norm\", F.regexp_replace(F.col(\"ZIP\"), \"[^0-9]\", \"\"))\n",
    ")\n",
    "\n",
    "print(\">>> income cleaned schema:\")\n",
    "income.printSchema()\n",
    "income.select(\"ZIP\",\"ZIP_norm\",\"median_income_household\").show(10, truncate=False); _lap(\"Prepare income (show)\")\n",
    "\n",
    "\n",
    "# Income per Community(Blocks) - Join\n",
    "\n",
    "blocks_norm = (blocks\n",
    "    .withColumn(\"ZCTA20_norm\", F.regexp_replace(F.trim(F.col(\"ZCTA20\")), \"[^0-9]\", \"\"))\n",
    "    .filter(F.col(\"ZCTA20_norm\").isNotNull() & (F.col(\"ZCTA20_norm\") != \"\"))\n",
    ")\n",
    "\n",
    "income_for_join = income.select(\"ZIP_norm\", \"median_income_household\")\n",
    "\n",
    "blocks_income = blocks_norm.join(\n",
    "    income_for_join,\n",
    "    blocks_norm[\"ZCTA20_norm\"] == income_for_join[\"ZIP_norm\"],\n",
    "    \"left\"\n",
    ")\n",
    "\n",
    "print(\">>> blocks rows (with ZCTA20_norm):\", blocks_norm.count())\n",
    "print(\">>> blocks_income rows (after left join):\", blocks_income.count()); _lap(\"Join ZCTA ⟷ ZIP (counts)\")\n",
    "blocks_income.select(\"COMM\",\"ZCTA20\",\"ZCTA20_norm\",\"median_income_household\").show(10, truncate=False)\n",
    "\n",
    "-\n",
    "print(\"\\n== Spark plan: ZCTA ⟷ ZIP (blocks_norm ⋈ income_for_join) ==\")\n",
    "blocks_income.explain(mode=\"formatted\"); _lap(\"Explain ZCTA ⟷ ZIP\")\n",
    "\n",
    "\n",
    "# Aggregation per COMM\n",
    "\n",
    "blocks_by_comm = (blocks_income\n",
    "    .groupBy(\"COMM\")\n",
    "    .agg(\n",
    "        F.sum(\"POP20\").alias(\"total_pop\"),\n",
    "        F.sum(\"HOUSING20\").alias(\"total_households\"),\n",
    "        (F.sum(F.col(\"HOUSING20\") * F.col(\"median_income_household\")) / F.sum(\"HOUSING20\")).alias(\"mean_household_income_w\"),\n",
    "        F.sum(F.col(\"HOUSING20\") * F.col(\"median_income_household\")).alias(\"total_household_income\")\n",
    "    )\n",
    "    .withColumn(\"per_capita_income\", F.col(\"total_household_income\") / F.col(\"total_pop\"))\n",
    ")\n",
    "\n",
    "print(\">>> blocks_by_comm rows:\", blocks_by_comm.count()); _lap(\"Aggregate by COMM (count)\")\n",
    "blocks_by_comm.select(\"COMM\",\"total_pop\",\"total_households\",\"mean_household_income_w\",\"per_capita_income\") \\\n",
    "              .orderBy(F.col(\"per_capita_income\").desc_nulls_last()) \\\n",
    "              .show(20, truncate=False)\n",
    "\n",
    "# Crimes Per Community - Join\n",
    "print(\">>> Running spatial join ...\", SPATIAL_JOIN)\n",
    "\n",
    "if SPATIAL_JOIN.lower() == \"covers\":\n",
    "    join_sql = \"\"\"\n",
    "        SELECT c.crime_id, c.YEAR_OCC, b.COMM\n",
    "        FROM crimes_geom c\n",
    "        JOIN blocks_geom b ON ST_Covers(b.geom, c.crime_geom)\n",
    "    \"\"\"\n",
    "elif SPATIAL_JOIN.lower() == \"contains\":\n",
    "    join_sql = \"\"\"\n",
    "        SELECT c.crime_id, c.YEAR_OCC, b.COMM\n",
    "        FROM crimes_geom c\n",
    "        JOIN blocks_geom b ON ST_Contains(b.geom, c.crime_geom)\n",
    "    \"\"\"\n",
    "else:  # intersects\n",
    "    join_sql = \"\"\"\n",
    "        SELECT c.crime_id, c.YEAR_OCC, b.COMM\n",
    "        FROM crimes_geom c\n",
    "        JOIN blocks_geom b ON ST_Intersects(b.geom, c.crime_geom)\n",
    "    \"\"\"\n",
    "\n",
    "crimes_with_comm_raw = spark.sql(join_sql)\n",
    "\n",
    "\n",
    "print(\"\\n== Spark plan: Spatial join (crimes_geom ⋈ blocks_geom) ==\")\n",
    "crimes_with_comm_raw.explain(mode=\"formatted\"); _lap(\"Explain spatial join\")\n",
    "\n",
    "# Tie-break (1 COMM ανά crime)\n",
    "w = Window.partitionBy(\"crime_id\").orderBy(F.col(\"COMM\").asc())\n",
    "crimes_with_comm = (crimes_with_comm_raw\n",
    "    .withColumn(\"rk\", F.row_number().over(w))\n",
    "    .filter(F.col(\"rk\") == 1)\n",
    "    .drop(\"rk\")\n",
    ")\n",
    "\n",
    "print(\">>> crimes_with_comm rows:\", crimes_with_comm.count()); _lap(\"Tie-break (count)\")\n",
    "crimes_with_comm.show(20, truncate=False)\n",
    "\n",
    "\n",
    "print(\"\\n== Spark plan: After tie-break (row_number / filter rk==1) ==\")\n",
    "crimes_with_comm.explain(mode=\"formatted\"); _lap(\"Explain tie-break\")\n",
    "\n",
    "# Crimes Per Community\n",
    "crime_counts_by_comm = crimes_with_comm.groupBy(\"COMM\").agg(F.count(\"*\").alias(\"crime_count_2020_2021\"))\n",
    "print(\">>> crime_counts_by_comm rows:\", crime_counts_by_comm.count()); _lap(\"Crime counts per COMM (count)\")\n",
    "crime_counts_by_comm.orderBy(F.col(\"crime_count_2020_2021\").desc()).show(20, truncate=False)\n",
    "\n",
    "# Final Stat Blocks\n",
    "area_stats = (blocks_by_comm\n",
    "    .join(crime_counts_by_comm, \"COMM\", \"left\")\n",
    "    .fillna({\"crime_count_2020_2021\": 0})\n",
    ")\n",
    "\n",
    "print(\">>> area_stats rows:\", area_stats.count()); _lap(\"Join area_stats (count)\")\n",
    "area_stats.select(\"COMM\",\"per_capita_income\",\"total_pop\",\"crime_count_2020_2021\") \\\n",
    "          .orderBy(F.col(\"per_capita_income\").desc_nulls_last()).show(30, truncate=False)\n",
    "\n",
    "# KPI: crimes per 1k people per year\n",
    "area_stats = (area_stats\n",
    "    .withColumn(\n",
    "        \"avg_annual_crime_per_person\",\n",
    "        F.when(F.col(\"total_pop\") > 0, F.col(\"crime_count_2020_2021\") / (2.0 * F.col(\"total_pop\"))).otherwise(F.lit(None).cast(\"double\"))\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"crime_per_1k_per_year\",\n",
    "        F.when(F.col(\"total_pop\") > 0, 1000.0 * F.col(\"crime_count_2020_2021\") / (2.0 * F.col(\"total_pop\"))).otherwise(F.lit(None).cast(\"double\"))\n",
    "    )\n",
    "    .cache()\n",
    ")\n",
    "\n",
    "print(\">>> area_stats with avg_annual_crime_per_person (sample):\")\n",
    "area_stats.select(\"COMM\",\"per_capita_income\",\"crime_per_1k_per_year\",\"avg_annual_crime_per_person\",\"total_pop\",\"crime_count_2020_2021\") \\\n",
    "          .orderBy(\"COMM\").show(30, truncate=False); _lap(\"Compute KPIs (show)\")\n",
    "\n",
    "# ----- Pearson (overall) -----\n",
    "overall_corr = area_stats.select(\"per_capita_income\",\"avg_annual_crime_per_person\") \\\n",
    "                         .na.drop().stat.corr(\"per_capita_income\",\"avg_annual_crime_per_person\")\n",
    "print(\"Overall correlation (all COMM):\", overall_corr); _lap(\"Overall correlation\")\n",
    "\n",
    "# ----- Spearman (overall) -----\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.stat import Correlation\n",
    "\n",
    "_vec = VectorAssembler(inputCols=[\"per_capita_income\",\"avg_annual_crime_per_person\"], outputCol=\"features\")\n",
    "_overall_vec = _vec.transform(\n",
    "    area_stats.select(\"per_capita_income\",\"avg_annual_crime_per_person\").na.drop()\n",
    ").select(\"features\")\n",
    "_overall_spearman = Correlation.corr(_overall_vec, \"features\", method=\"spearman\").head()[0].toArray()[0,1]\n",
    "print(\"Overall correlation (all COMM) [Spearman]:\", _overall_spearman)\n",
    "\n",
    "top10 = area_stats.orderBy(F.col(\"per_capita_income\").desc_nulls_last()).limit(10)\n",
    "bottom10 = area_stats.orderBy(F.col(\"per_capita_income\").asc_nulls_last()).limit(10)\n",
    "\n",
    "print(\">>> top10 rows:\", top10.count())\n",
    "print(\">>> bottom10 rows:\", bottom10.count()); _lap(\"Top/Bottom selection (counts)\")\n",
    "\n",
    "# ----- Pearson (Top-10 / Bottom-10) -----\n",
    "top10_corr = top10.select(\"per_capita_income\",\"avg_annual_crime_per_person\").na.drop() \\\n",
    "                  .stat.corr(\"per_capita_income\",\"avg_annual_crime_per_person\")\n",
    "bottom10_corr = bottom10.select(\"per_capita_income\",\"avg_annual_crime_per_person\").na.drop() \\\n",
    "                        .stat.corr(\"per_capita_income\",\"avg_annual_crime_per_person\")\n",
    "\n",
    "print(\"Correlation (Top-10 richest COMM):\", top10_corr)\n",
    "print(\"Correlation (Bottom-10 poorest COMM):\", bottom10_corr); _lap(\"Top/Bottom correlations\")\n",
    "\n",
    "# ----- Spearman (Top-10 / Bottom-10) -----\n",
    "_top10_vec = _vec.transform(\n",
    "    top10.select(\"per_capita_income\",\"avg_annual_crime_per_person\").na.drop()\n",
    ").select(\"features\")\n",
    "_bottom10_vec = _vec.transform(\n",
    "    bottom10.select(\"per_capita_income\",\"avg_annual_crime_per_person\").na.drop()\n",
    ").select(\"features\")\n",
    "\n",
    "_top10_spearman = Correlation.corr(_top10_vec, \"features\", method=\"spearman\").head()[0].toArray()[0,1]\n",
    "_bottom10_spearman = Correlation.corr(_bottom10_vec, \"features\", method=\"spearman\").head()[0].toArray()[0,1]\n",
    "\n",
    "print(\"Correlation (Top-10 richest COMM) [Spearman]:\", _top10_spearman)\n",
    "print(\"Correlation (Bottom-10 poorest COMM) [Spearman]:\", _bottom10_spearman)\n",
    "\n",
    "print(\"\\nTop-10 COMM by per_capita_income:\")\n",
    "top10.select(\"COMM\",\"per_capita_income\",\"crime_per_1k_per_year\",\"avg_annual_crime_per_person\",\"total_pop\",\"crime_count_2020_2021\").show(truncate=False)\n",
    "print(\"\\nBottom-10 COMM by per_capita_income:\")\n",
    "bottom10.select(\"COMM\",\"per_capita_income\",\"crime_per_1k_per_year\",\"avg_annual_crime_per_person\",\"total_pop\",\"crime_count_2020_2021\").show(truncate=False); _lap(\"Final shows\")\n",
    "\n",
    "\n",
    "TOTAL_SEC = time.time() - _T0\n",
    "print(f\"\\n>>> [timing] TOTAL EXECUTION TIME: {TOTAL_SEC:.2f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea3eff9-fb8c-4149-a38e-88d1149eb3d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sparkmagic (PySpark)",
   "language": "python",
   "name": "pysparkkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "python",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "pyspark",
   "pygments_lexer": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
